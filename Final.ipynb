{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import load_model\n",
    "from joblib import load\n",
    "from skimage.transform import resize\n",
    "from joblib import load\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the webcam and MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the age and gender models\n",
    "age_net = cv2.dnn.readNetFromCaffe('age_deploy.prototxt', 'age_net.caffemodel')\n",
    "gender_net = cv2.dnn.readNetFromCaffe('gender_deploy.prototxt', 'gender_net.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the fashion analysis model\n",
    "fashion_model = load_model(\"fashion_model_1.h5\")\n",
    "\n",
    "# Load the ad prediction model\n",
    "ad_model = load(\"random_forest_model.pkl\")\n",
    "\n",
    "# Load the scaler\n",
    "scaler = load(\"rf_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the age, gender, dress and ad labels\n",
    "age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "gender_list = ['male', 'female']\n",
    "dress_list=['casual', 'formal','modern','sportswear']\n",
    "ad_list=['casual wear','electronics','formal wear','luxury','sportswear','travel and leisure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casual wear.png',\n",
       " 'electronics.png',\n",
       " 'formal wear.png',\n",
       " 'luxury.png',\n",
       " 'sportswear.png',\n",
       " 'travel and leisure.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads=os.listdir('Ads')\n",
    "ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertisement=[]\n",
    "for ad in ads:\n",
    "    advert=cv2.imread('Ads'+\"/\"+ad)\n",
    "    advertisement.append(advert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Age: (25-32), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Age: (25-32), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Age: (25-32), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877ms/step\n",
      "Age: (25-32), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849ms/step\n",
      "Age: (25-32), Gender: male, Dress: modern, Ad: casual wear\n",
      "Age: (4-6), Gender: male, Dress: modern, Ad: casual wear\n",
      "Age: (4-6), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947ms/step\n",
      "Age: (48-53), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935ms/step\n",
      "Age: (48-53), Gender: male, Dress: casual, Ad: sportswear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949ms/step\n",
      "Age: (25-32), Gender: male, Dress: casual, Ad: sportswear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991ms/step\n",
      "Age: (48-53), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974ms/step\n",
      "Age: (48-53), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922ms/step\n",
      "Age: (48-53), Gender: male, Dress: casual, Ad: sportswear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965ms/step\n",
      "Age: (48-53), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971ms/step\n",
      "Age: (48-53), Gender: male, Dress: casual, Ad: sportswear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912ms/step\n",
      "Age: (48-53), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Age: (25-32), Gender: female, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955ms/step\n",
      "Age: (48-53), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892ms/step\n",
      "Age: (25-32), Gender: male, Dress: modern, Ad: casual wear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860ms/step\n",
      "Age: (25-32), Gender: female, Dress: modern, Ad: casual wear\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB for MediaPipe\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces using MediaPipe\n",
    "    results = face_detection.process(rgb_frame)\n",
    "\n",
    "    # Initialize variables for selecting the best face\n",
    "    largest_face = None\n",
    "    largest_area = 0\n",
    "\n",
    "    # Check if faces are detected\n",
    "    if results.detections:\n",
    "        for face in results.detections:\n",
    "            bboxC = face.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x = int(bboxC.xmin * iw)\n",
    "            y = int(bboxC.ymin * ih)\n",
    "            w = int(bboxC.width * iw) + x\n",
    "            h = int(bboxC.height * ih) + y\n",
    "\n",
    "            # Ensure coordinates are within image boundaries\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            w, h = min(iw, w), min(ih, h)\n",
    "\n",
    "            # Calculate the area of the bounding box\n",
    "            area = (w - x) * (h - y)\n",
    "\n",
    "            # Update the largest face\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_face = (x, y, w, h)\n",
    "\n",
    "        # Process only the largest face\n",
    "        if largest_face:\n",
    "            x, y, w, h = largest_face\n",
    "\n",
    "            # Crop the face from the original frame\n",
    "            face_crop = frame[y:h, x:w]\n",
    "\n",
    "            # Check if face_crop is valid and not empty\n",
    "            if face_crop.size == 0:\n",
    "                continue  # Skip if face_crop is empty\n",
    "\n",
    "            # Ensure face_crop has correct dimensions\n",
    "            if face_crop.shape[0] < 1 or face_crop.shape[1] < 1:\n",
    "                continue  # Skip if face_crop has invalid dimensions\n",
    "\n",
    "            # Run age and gender prediction using OpenCV\n",
    "            age_blob = cv2.dnn.blobFromImage(face_crop, 1, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "            gender_blob = cv2.dnn.blobFromImage(face_crop, 1, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "            age_net.setInput(age_blob)\n",
    "            gender_net.setInput(gender_blob)\n",
    "            age_preds = age_net.forward()\n",
    "            gender_preds = gender_net.forward()\n",
    "\n",
    "            # Get the predicted age and gender\n",
    "            age = age_list[age_preds[0].argmax()]\n",
    "\n",
    "            if age in ['(0-2)', '(4-6)', '(8-12)']:\n",
    "                continue\n",
    "            elif age =='(15-20)':\n",
    "                age_cat=0\n",
    "            elif age =='(25-32)':\n",
    "                age_cat=2\n",
    "            elif age =='(38-43)':\n",
    "                age_cat=4\n",
    "            elif age =='(48-53)':\n",
    "                age_cat=5\n",
    "            \n",
    "            gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "            if gender =='male':\n",
    "                gender_cat=1\n",
    "            elif gender == \"female\": \n",
    "                gender_cat=0\n",
    "\n",
    "            \n",
    "            #dress category prediction\n",
    "\n",
    "            d_image=resize(rgb_frame,(224,224))\n",
    "            d_image=d_image.reshape(1,224,224,3)\n",
    "            prediction=fashion_model.predict(d_image)\n",
    "            ind=prediction.argmax(axis=1)\n",
    "            dress=dress_list[ind[0]]\n",
    "\n",
    "            if dress =='casual':\n",
    "                dress_cat=0\n",
    "            elif dress == \"formal\": \n",
    "                dress_cat=1\n",
    "            elif dress == \"modern\": \n",
    "                dress_cat=2\n",
    "            elif dress == \"sportswear\": \n",
    "                dress_cat=3\n",
    "\n",
    "            #Ad prediction\n",
    "\n",
    "            ad_pred=ad_model.predict(scaler.transform([[gender_cat,dress_cat,gender_cat]]))\n",
    "            ad_val = ad_pred[0]\n",
    "            ad_cat = ad_list[ad_val]\n",
    "\n",
    "\n",
    "            if ad_cat =='casual wear':\n",
    "                aad=0\n",
    "            elif ad_cat =='electronics':\n",
    "                aad=1\n",
    "            elif ad_cat =='formal wear':\n",
    "                aad=2\n",
    "            elif ad_cat =='luxury':\n",
    "                aad=3\n",
    "            elif ad_cat =='sportswear':\n",
    "                aad=4\n",
    "            elif ad_cat =='travel and leisure':\n",
    "                aad=5\n",
    "            \n",
    "            ad=advertisement[aad]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Display the results\n",
    "            cv2.putText(frame, f\"Age: {age}, Gender: {gender}, Dress: {dress}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame, (x, y), (w, h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow(\"SmartAd\",ad)\n",
    "    # cv2.imshow(\"SmartAd\", frame)\n",
    "    print(f\"Age: {age}, Gender: {gender}, Dress: {dress}, Ad: {ad_list[aad]}\")\n",
    "\n",
    "    # Exit on key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
